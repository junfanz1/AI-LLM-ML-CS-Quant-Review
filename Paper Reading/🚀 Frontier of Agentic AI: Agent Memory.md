# üöÄ Frontier of Agentic AI: Agent Memory ‚Äî Key Takeaways
Attended Google‚Äôs fascinating meetup on hashtag#Agent hashtag#Memory, frontiers in building truly Agentic AI systems. Big thank you to Ran Li, Warren(Weilun) Chen and our guest speakers for the insightful event!

# [LinkedIn Post](https://www.linkedin.com/posts/junfan-zhu_agent-memory-activity-7380113422757277696-oaAc?utm_source=share&utm_medium=member_desktop&rcm=ACoAABxP-p0BpUNGDf347aKh_1uJAPzG4er0As8)

## 1Ô∏è‚É£ Lenjoy Lin, CoFounder @ Genspark ‚Äî Product-Driven Memory Architecture
- Challenges: context window & token budget remain bottlenecks.
- Memory extends reasoning beyond sessions.
- Session-level vs. Application-level: Session = short-term continuity; Application = RAG for longer-term relevance.
- Over-personalization isn‚Äôt ideal ‚Äî generalization matters more for consumer AI.
- General vs. vertical: ‚ÄúDifferent products for different scenarios ‚Äî the world will be more diverse.‚Äù We won‚Äôt have one general agent; specialized, application-layer agents will dominate.
- Vision: democratize professional tools, lower R&D barriers, empower creativity.

## 2Ô∏è‚É£ Deshraj Yadav, CTO & CoFounder @ Mem0 ‚Äî Model-Agnostic, Self-Improving Memory
- Retrieval‚â†memory. Agent memory should be independent, model-agnostic, self-improving.
- Architecture:
  - Extraction phase: parse info from conversations or actions.
  - Update phase: decide what and where to store ‚Äî into a knowledge graph or KV/vector DB.
- Knowledge graphs are optional, used only when structure matters.
- Vision: ‚ÄúMemory Passport‚Äù as universal as email ‚Äî standard identity layer for all agents.
- Use cases: Patient Context Continuity, Adaptive Learning, Cross-Session Shopping, Contextual Issue Resolution, Relationship Memory.

## 3Ô∏è‚É£ Research Scientist @ Google DeepMind ‚Äî Memory as Reasoning Skill
- Agent memory is not storage ‚Äî but reasoning skill. Memory acts as cognitive scaffolding, not infra. Human memory generalizes; agents reuse procedural knowledge.
- Optimization paths: 
  - Context editing: carry fewer tokens next time.
  - Long-term memory: rebuild abstractions from past episodes.
- Not just retrieval ‚Äî it‚Äôs distillation, indexing, reuse.
- Echoes Claude 4.5‚Äôs tool-aware models: can model understand and invoke memory tools correctly?
- Hallucination = not knowing when to use memory.
- Parametric vs. Non-parametric memory: weights vs. external stores.
- Key: what kind of data to store for reasoning. If a problem can be distilled, it can be retrieved and solved.
- Future: self-verifying, recursive agents that can critique or even submit PRs autonomously.
- AGI may emerge from 1000-step reasoning chains connecting abstract dots.

## 4Ô∏è‚É£ Roundtable
- Memory = infra + cognition.
- Avoid over engineering; stay flexible as models evolve.
- Trend: RAG ‚Üí memory-aware models ‚Üí reasoning-integrated agents.
- Frontier: teach models when & how to use memory tools.

## üí° Thoughts
Agent Memory shifts from retrieval layer into reasoning substrate ‚Äî bridging infrastructure, cognition, and autonomy. Can we teach models to learn their own ‚Äúupdate policy‚Äù ‚Äî deciding what to retain, compress, or discard, independent of the base LLM? Curious to hear your thoughts: where cognition meets infrastructure in agent design.
